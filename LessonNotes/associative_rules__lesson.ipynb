{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies Installation\n",
    "Before we get started, let's make sure we have all dependencies installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "! pip3 install pymongo dateparser sklearn pandas numpy pprint scipy matplotlib seaborn mlxtend\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Association Rules\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Necessary Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dependencies\n",
    "import dateparser\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "from mlxtend.preprocessing import one_hot\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\", palette=\"muted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Initial Setup\n",
    "\n",
    "We'll create a dataframe with some made up transactions to illustrate the apriori algorithm and association rules. The dictionary key will represent the product bought, and the number will represent the quantity bought."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transactions = [\n",
    "    {\n",
    "        \"beer\": 1,\n",
    "        \"chips\": 2,\n",
    "        \"salsa\": 1,\n",
    "    },\n",
    "    {\n",
    "        \"chips\": 1,\n",
    "        \"salsa\": 1,\n",
    "        \"chocolate\": 3\n",
    "    },\n",
    "    {\n",
    "        \"chocolate\": 2,\n",
    "        \"diapers\": 1,\n",
    "        \"beer\": 2\n",
    "    },\n",
    "    {\n",
    "        \"chips\": 2,\n",
    "        \"salsa\": 1,\n",
    "        \"chocolate\": 2\n",
    "    },\n",
    "    {\n",
    "        \"diapers\": 3,\n",
    "        \"chips\": 1,\n",
    "        \"salsa\": 2,\n",
    "        \"beer\": 2\n",
    "    },\n",
    "    {\n",
    "        \"diapers\": 2,\n",
    "        \"chips\": 1,\n",
    "        \"salsa\": 1,\n",
    "        \"chocolate\": 4,\n",
    "        \"beer\": 3\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = pd.DataFrame.from_dict(transactions)\n",
    "transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting rid of NaN Values\n",
    "\n",
    "We need to get rid of NaN values, so we'll use a utility method from Pandas to replace them with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions.fillna(0, inplace=True)\n",
    "transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot Encoding\n",
    "\n",
    "We need to one hot encode the data, so that 1 means they bought the item and 0 means they didn't. We'll quickly search the dataframe and replace values greater than 1 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oh = transactions\n",
    "for column in oh.columns:\n",
    "    oh.loc[oh[column] > 0, column] = 1\n",
    "oh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apriori\n",
    "\n",
    "The first step is to use the apriori algorithm. This will give us our frequent itemsets and their support.\n",
    "\n",
    "The support of an itemset is the proportion of transaction in the collection in which the itemset appears. It signifies the popularity of an itemset.\n",
    "\n",
    "Given the above information, we have 6 transactions. Of those, beer appears in 4 of them. So, we'd expect the itemset `[beer]` to have a support value of `4/6` or `.666666667`.\n",
    "\n",
    "Going through all of them, we can build itemsets that are just one item and calculate their support."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our 1 item itemsets, let's build up our 2 item itemsets. So, if an itemset is [a, b] where a is chips and b is salse, the support is the ratio of the apperance of itemset `[a, b]` in all transactions. We would do this until we have exhausted all possible itemsets.\n",
    "\n",
    "Also of key importance is being able to define some minimum threshold for which we do not care about that itemset.\n",
    "\n",
    "For this, we'll use the `apriori` algorithm from `mlxtend`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assocs = apriori(oh, min_support=0.5, use_colnames=True)\n",
    "\n",
    "assocs =assocs.sort_values(by='support', ascending=False)\n",
    "assocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = association_rules(assocs, min_threshold=0.5)\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', 5):\n",
    "    display(rules.sort_values(by='lift', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pymongo Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pymongo driver configuration\n",
    "course_cluster_uri = \"mongodb://agg-student:agg-password@cluster0-shard-00-00-jxeqq.mongodb.net:27017,cluster0-shard-00-01-jxeqq.mongodb.net:27017,cluster0-shard-00-02-jxeqq.mongodb.net:27017/test?ssl=true&replicaSet=Cluster0-shard-0&authSource=admin\"\n",
    "course_client = pymongo.MongoClient(course_cluster_uri)\n",
    "orders = course_client['coursera-agg']['orders']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting our data from MongoDB\n",
    "\n",
    "We'll need to construct a one-hot encoded dataframe. This means that for every document, convert the information into the purchases array into something like:\n",
    "\n",
    "```\n",
    "{\n",
    "    ...,\n",
    "    \"purchases\": [\n",
    "        {\n",
    "          \"description\": \"WHITE WIRE EGG HOLDER\",\n",
    "          \"quantity\": 36,\n",
    "          \"stock_code\": \"84880\",\n",
    "          \"unit_price\": 4.95\n",
    "        },\n",
    "        {\n",
    "          \"description\": \"JUMBO  BAG BAROQUE BLACK WHITE\",\n",
    "          \"quantity\": 100,\n",
    "          \"stock_code\": \"85099C\",\n",
    "          \"unit_price\": 1.65\n",
    "        },\n",
    "        {\n",
    "          \"description\": \"JUMBO BAG RED RETROSPOT\",\n",
    "          \"quantity\": 100,\n",
    "          \"stock_code\": \"85099B\",\n",
    "          \"unit_price\": 1.65\n",
    "        }\n",
    "      ],\n",
    "  }\n",
    "  ```\n",
    "  into\n",
    "  ```\n",
    "{\n",
    "    \"84880\": 1,\n",
    "    \"85099C\": 1,\n",
    "    \"85099B\": 1,\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_projection = {\n",
    "    \"$replaceRoot\": {\n",
    "            \"newRoot\":  {\n",
    "                \"$arrayToObject\": {\n",
    "                    \"$map\": {\n",
    "                        \"input\": \"$purchases\",\n",
    "                        \"in\": {\n",
    "                            \"k\": \"$$this.stock_code\",\n",
    "                            \"v\": 1\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "    }\n",
    "            \n",
    "}\n",
    "\n",
    "print(json.dumps(order_projection, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing the Pipeline\n",
    "\n",
    "That's it! We will use our one stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = [\n",
    "    order_projection\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing the pandas Dataframe from MongoDB\n",
    "\n",
    "Here you will need to construct the DataFrame. Assign it to the variabled `df` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(list(orders.aggregate(pipeline)))\n",
    "df.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing the NaN values\n",
    "\n",
    "We will use the Pandas DataFrame [fillna](http://github.com/pandas-dev/pandas/blob/v0.21.0/pandas/core/frame.py#L3029-L3035) method to fill in NaN values for us with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(0, inplace=True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Association"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apriori\n",
    "First, we'll use the `apriori` algorithm from `mlxtend` to extract frequent itemsets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "assocs = apriori(df, min_support=0.02, use_colnames=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', 5):\n",
    "    assocs =assocs.sort_values(by='support', ascending=False)\n",
    "    display(assocs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Association Rules\n",
    "\n",
    "Now we form the association rules. Try adjusting the `min_threshold` along with the `metric` to find interesting associations. For example, which class appears to be highly associated with `parents_children`? Go back and add a one-hot encoding function for `parents_children` and see if the results are more clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rules = association_rules(assocs, metric=\"lift\", min_threshold=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', 5):\n",
    "    display(rules.sort_values(by='lift', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\n",
    "    \"$match\": {\n",
    "        \"_id.stock_code\": { \"$in\": [\"22697\", \"22698\", \"22699\"]}\n",
    "    }\n",
    "}\n",
    "\n",
    "project = {\n",
    "    \"$project\": { \"_id\": 0, \"purchases.stock_code\": 1, \"purchases.description\": 1}\n",
    "}\n",
    "\n",
    "pipeline = [\n",
    "    {\n",
    "        \"$unwind\": \"$purchases\"\n",
    "    },\n",
    "    {\n",
    "        \"$group\": {\n",
    "            \"_id\": {\n",
    "                \"stock_code\": \"$purchases.stock_code\",\n",
    "                \"description\": \"$purchases.description\"\n",
    "            }\n",
    "            \n",
    "        }\n",
    "    },\n",
    "    query\n",
    "]\n",
    "display(list(orders.aggregate(pipeline)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
